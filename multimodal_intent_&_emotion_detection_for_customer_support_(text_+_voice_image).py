# -*- coding: utf-8 -*-
"""Multimodal Intent & Emotion Detection for Customer Support (Text + Voice/Image).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12MhbDDEo8ewLcplTBgU2-wUTpZmGddro
"""

!pip install -q transformers datasets torchaudio accelerate soundfile pillow

from datasets import load_dataset
import numpy as np

# Load ONE audio sample (streaming → no disk usage)
dataset = load_dataset(
    "librispeech_asr",
    "clean",
    split="validation",
    streaming=True
)

sample = next(iter(dataset))
audio_decoder = sample["audio"]

# Decode using torchcodec (works in latest HF)
samples = audio_decoder.get_all_samples()

audio_array = samples.data.numpy()
sampling_rate = samples.sample_rate

# Convert stereo → mono
if audio_array.ndim > 1:
    audio_array = audio_array.mean(axis=0)

audio_array = audio_array.astype(np.float32)

print("Audio ready:", audio_array.shape, sampling_rate)

from transformers import pipeline

asr_pipeline = pipeline(
    "automatic-speech-recognition",
    model="facebook/wav2vec2-base-960h",
    device=0
)

voice_text = asr_pipeline(audio_array)["text"]
print("Voice Text:", voice_text)

# Customer text (email / chat)
text_input = """
My order arrived late and the screen is cracked.
I want a refund immediately.
"""

# Image caption (from BLIP or simulated)
image_description = "Image shows a smartphone with a cracked screen."

combined_text = f"""
Customer Text:
{text_input}

Voice Transcription:
{voice_text}

Image Description:
{image_description}
"""

print(combined_text)

from transformers import pipeline

intent_classifier = pipeline(
    "zero-shot-classification",
    model="facebook/bart-large-mnli",
    device=0
)

intent_labels = [
    "refund request",
    "delivery delay",
    "product damage",
    "technical issue",
    "praise",
    "general complaint"
]

intent_result = intent_classifier(
    combined_text,
    candidate_labels=intent_labels
)

intent = intent_result["labels"][0]
print("Detected Intent:", intent)

emotion_classifier = pipeline(
    "text-classification",
    model="j-hartmann/emotion-english-distilroberta-base",
    device=0
)

emotion_output = emotion_classifier(combined_text)
emotion = emotion_output[0]["label"]

print("Detected Emotion:", emotion)

urgent_keywords = [
    "refund", "immediately", "now", "asap", "unacceptable", "worst"
]

urgency = "low"

if any(word in combined_text.lower() for word in urgent_keywords):
    urgency = "high"
elif emotion in ["anger", "fear", "disgust"]:
    urgency = "medium"

print("Urgency Level:", urgency)

aspect_sentiment = {}

if "late" in combined_text.lower():
    aspect_sentiment["delivery"] = "negative"

if "crack" in combined_text.lower() or "broken" in combined_text.lower():
    aspect_sentiment["product_quality"] = "negative"

if "support" in combined_text.lower():
    aspect_sentiment["customer_support"] = "negative"

print("Aspect Sentiment:", aspect_sentiment)

def agent_decision(intent, emotion, urgency):
    if urgency == "high" and emotion in ["anger", "disgust"]:
        return "escalate_to_human"
    elif "refund" in intent:
        return "generate_return_label"
    elif "technical" in intent:
        return "search_knowledge_base"
    else:
        return "auto_reply"

action = agent_decision(intent, emotion, urgency)
print("Agent Action:", action)

response_generator = pipeline(
    "text-generation",
    model="google/flan-t5-base",
    device=0
)

prompt = f"""
You are a customer support assistant.

Customer emotion: {emotion}
Urgency level: {urgency}
Intent: {intent}
Issues: {aspect_sentiment}

Respond empathetically and professionally.
"""

response = response_generator(
    prompt,
    max_new_tokens=150,
    do_sample=False
)[0]["generated_text"]

print("AI Response:")
print(response)

print("\n--- FINAL SYSTEM OUTPUT ---")
print("Intent:", intent)
print("Emotion:", emotion)
print("Urgency:", urgency)
print("Aspect Sentiment:", aspect_sentiment)
print("Agent Action:", action)
print("Response:", response)